# This file was autogenerated by uv via the following command:
#    uv export --no-hashes
aiofiles==24.1.0
    # via gradio
annotated-doc==0.0.4
    # via fastapi
annotated-types==0.7.0
    # via pydantic
antlr4-python3-runtime==4.9.3
    # via omegaconf
anyio==4.7.0
    # via
    #   gradio
    #   httpx
    #   openai
    #   starlette
appnope==0.1.4 ; sys_platform == 'darwin'
    # via ipykernel
asttokens==3.0.0
    # via stack-data
audioread==3.1.0
    # via librosa
av==16.0.1
    # via faster-whisper
brotli==1.2.0
    # via gradio
catalogue==2.0.10
    # via srsly
certifi==2024.12.14
    # via
    #   httpcore
    #   httpx
    #   requests
cffi==1.17.1
    # via
    #   cryptography
    #   pyzmq
    #   soundfile
cfgv==3.5.0
    # via pre-commit
charset-normalizer==3.4.0
    # via
    #   pdfminer-six
    #   requests
chatterbox-tts @ git+https://github.com/resemble-ai/chatterbox.git@ed27b95ee46b95be201147bafe5ca85ac57ac4f2
    # via audiobook
click==8.1.8
    # via
    #   audiobook
    #   nltk
    #   typer
    #   uvicorn
colorama==0.4.6 ; sys_platform == 'win32'
    # via
    #   click
    #   ipython
    #   loguru
    #   pytest
    #   tqdm
coloredlogs==15.0.1
    # via onnxruntime
comm==0.2.2
    # via ipykernel
conformer==0.3.2
    # via chatterbox-tts
cryptography==44.0.0
    # via pdfminer-six
ctranslate2==4.6.2
    # via faster-whisper
debugpy==1.8.11
    # via ipykernel
decorator==5.1.1
    # via
    #   ipython
    #   librosa
deprecated==1.3.1
    # via pykakasi
diffusers==0.29.0
    # via chatterbox-tts
distlib==0.4.0
    # via virtualenv
distro==1.9.0
    # via openai
einops==0.8.1
    # via
    #   conformer
    #   s3tokenizer
elevenlabs==1.50.3
    # via audiobook
executing==2.1.0
    # via stack-data
fastapi==0.127.0
    # via gradio
faster-whisper==1.2.1
    # via audiobook
ffmpy==1.0.0
    # via gradio
filelock==3.20.1
    # via
    #   diffusers
    #   huggingface-hub
    #   torch
    #   transformers
    #   virtualenv
flatbuffers==25.12.19
    # via onnxruntime
fsspec==2025.12.0
    # via
    #   gradio-client
    #   huggingface-hub
    #   torch
future==1.0.0
    # via pyloudnorm
gradio==5.44.1
    # via chatterbox-tts
gradio-client==1.12.1
    # via gradio
groovy==0.1.2
    # via gradio
h11==0.14.0
    # via
    #   httpcore
    #   uvicorn
hf-xet==1.2.0 ; platform_machine == 'aarch64' or platform_machine == 'amd64' or platform_machine == 'arm64' or platform_machine == 'x86_64'
    # via huggingface-hub
httpcore==1.0.7
    # via httpx
httpx==0.28.1
    # via
    #   elevenlabs
    #   gradio
    #   gradio-client
    #   openai
    #   safehttpx
huggingface-hub==0.36.0
    # via
    #   diffusers
    #   faster-whisper
    #   gradio
    #   gradio-client
    #   tokenizers
    #   transformers
humanfriendly==10.0
    # via coloredlogs
identify==2.6.15
    # via pre-commit
idna==3.10
    # via
    #   anyio
    #   httpx
    #   requests
importlib-metadata==8.7.1
    # via diffusers
iniconfig==2.0.0
    # via pytest
ipykernel==6.29.5
    # via audiobook
ipython==8.31.0
    # via ipykernel
jaconv==0.4.1
    # via pykakasi
jedi==0.19.2
    # via ipython
jinja2==3.1.6
    # via
    #   gradio
    #   torch
jiter==0.8.2
    # via openai
joblib==1.4.2
    # via
    #   librosa
    #   nltk
    #   scikit-learn
jupyter-client==8.6.3
    # via ipykernel
jupyter-core==5.7.2
    # via
    #   ipykernel
    #   jupyter-client
lazy-loader==0.4
    # via librosa
levenshtein==0.27.3
    # via audiobook
librosa==0.11.0
    # via chatterbox-tts
llvmlite==0.46.0
    # via numba
loguru==0.7.3
    # via audiobook
markdown-it-py==4.0.0
    # via rich
markupsafe==3.0.3
    # via
    #   gradio
    #   jinja2
matplotlib-inline==0.1.7
    # via
    #   ipykernel
    #   ipython
mdurl==0.1.2
    # via markdown-it-py
ml-dtypes==0.5.4
    # via
    #   audiobook
    #   onnx
mpmath==1.3.0
    # via sympy
msgpack==1.1.2
    # via librosa
nest-asyncio==1.6.0
    # via ipykernel
networkx==3.6.1
    # via torch
nltk==3.9.1
    # via audiobook
nodeenv==1.10.0
    # via pre-commit
numba==0.63.1
    # via librosa
numpy==1.25.2
    # via
    #   chatterbox-tts
    #   ctranslate2
    #   diffusers
    #   gradio
    #   librosa
    #   ml-dtypes
    #   numba
    #   onnx
    #   onnxruntime
    #   pandas
    #   pyloudnorm
    #   s3tokenizer
    #   scikit-learn
    #   scipy
    #   soundfile
    #   soxr
    #   spacy-pkuseg
    #   transformers
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
    # via torch
    # via torch
    # via torch
    # via torch
    # via torch
    # via torch
    # via torch
    # via
    #   nvidia-cusolver-cu12
    #   torch
    # via torch
    # via torch
    # via
    #   nvidia-cufft-cu12
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
    #   torch
    # via torch
omegaconf==2.3.0
    # via chatterbox-tts
onnx==1.19.0
    # via s3tokenizer
onnxruntime==1.23.2
    # via faster-whisper
openai==1.58.1
    # via audiobook
orjson==3.11.5
    # via gradio
packaging==24.2
    # via
    #   gradio
    #   gradio-client
    #   huggingface-hub
    #   ipykernel
    #   lazy-loader
    #   onnxruntime
    #   pooch
    #   pytest
    #   transformers
pandas==2.1.0
    # via gradio
parso==0.8.4
    # via jedi
pdfminer-six==20231228
    # via pdfplumber
pdfplumber==0.11.4
    # via audiobook
pexpect==4.9.0 ; sys_platform != 'emscripten' and sys_platform != 'win32'
    # via ipython
pillow==11.0.0
    # via
    #   diffusers
    #   gradio
    #   pdfplumber
platformdirs==4.3.6
    # via
    #   jupyter-core
    #   pooch
    #   virtualenv
pluggy==1.5.0
    # via pytest
pooch==1.8.2
    # via librosa
pre-commit==4.5.1
    # via s3tokenizer
prompt-toolkit==3.0.48
    # via ipython
protobuf==6.33.2
    # via
    #   onnx
    #   onnxruntime
psutil==6.1.1
    # via ipykernel
ptyprocess==0.7.0 ; sys_platform != 'emscripten' and sys_platform != 'win32'
    # via pexpect
pure-eval==0.2.3
    # via stack-data
pycparser==2.22
    # via cffi
pydantic==2.10.4
    # via
    #   elevenlabs
    #   fastapi
    #   gradio
    #   openai
pydantic-core==2.27.2
    # via
    #   elevenlabs
    #   pydantic
pydub==0.25.1
    # via
    #   audiobook
    #   gradio
pygments==2.18.0
    # via
    #   ipython
    #   rich
pykakasi==2.3.0
    # via chatterbox-tts
pyloudnorm==0.1.1
    # via chatterbox-tts
pypdfium2==4.30.1
    # via pdfplumber
pyreadline3==3.5.4 ; sys_platform == 'win32'
    # via humanfriendly
pytest==8.3.4
python-dateutil==2.9.0.post0
    # via
    #   jupyter-client
    #   pandas
python-dotenv==1.0.1
    # via audiobook
python-multipart==0.0.21
    # via gradio
pytz==2025.2
    # via pandas
pywin32==308 ; platform_python_implementation != 'PyPy' and sys_platform == 'win32'
    # via jupyter-core
pyyaml==6.0.3
    # via
    #   ctranslate2
    #   gradio
    #   huggingface-hub
    #   omegaconf
    #   pre-commit
    #   transformers
pyzmq==26.2.0
    # via
    #   ipykernel
    #   jupyter-client
rapidfuzz==3.14.3
    # via levenshtein
regex==2024.11.6
    # via
    #   diffusers
    #   nltk
    #   transformers
requests==2.32.3
    # via
    #   diffusers
    #   elevenlabs
    #   huggingface-hub
    #   pooch
    #   transformers
resemble-perth==1.0.1
    # via chatterbox-tts
rich==14.2.0
    # via
    #   audiobook
    #   typer
ruff==0.14.10
    # via gradio
s3tokenizer==0.3.0
    # via chatterbox-tts
safehttpx==0.1.7
    # via gradio
safetensors==0.5.3
    # via
    #   chatterbox-tts
    #   diffusers
    #   transformers
scikit-learn==1.8.0
    # via librosa
scipy==1.16.3
    # via
    #   librosa
    #   pyloudnorm
    #   scikit-learn
semantic-version==2.10.0
    # via gradio
setuptools==80.9.0
    # via
    #   audiobook
    #   ctranslate2
shellingham==1.5.4 ; sys_platform != 'emscripten'
    # via typer
six==1.17.0
    # via python-dateutil
sniffio==1.3.1
    # via
    #   anyio
    #   openai
soundfile==0.13.1
    # via librosa
soxr==1.0.0
    # via librosa
spacy-pkuseg==1.0.1
    # via chatterbox-tts
srsly==2.5.2
    # via spacy-pkuseg
stack-data==0.6.3
    # via ipython
starlette==0.50.0
    # via
    #   fastapi
    #   gradio
sympy==1.13.1
    # via
    #   onnxruntime
    #   torch
threadpoolctl==3.6.0
    # via scikit-learn
tokenizers==0.20.3
    # via
    #   faster-whisper
    #   transformers
tomlkit==0.13.3
    # via gradio
    # via
    #   audiobook
    #   chatterbox-tts
    #   conformer
    #   s3tokenizer
    #   torchaudio
    # via
    #   audiobook
    #   chatterbox-tts
    #   s3tokenizer
tornado==6.4.2
    # via
    #   ipykernel
    #   jupyter-client
tqdm==4.67.1
    # via
    #   audiobook
    #   faster-whisper
    #   huggingface-hub
    #   nltk
    #   openai
    #   s3tokenizer
    #   transformers
traitlets==5.14.3
    # via
    #   comm
    #   ipykernel
    #   ipython
    #   jupyter-client
    #   jupyter-core
    #   matplotlib-inline
transformers==4.46.3
    # via chatterbox-tts
    # via torch
typer==0.20.1 ; sys_platform != 'emscripten'
    # via gradio
typing-extensions==4.12.2
    # via
    #   anyio
    #   elevenlabs
    #   fastapi
    #   gradio
    #   gradio-client
    #   huggingface-hub
    #   ipython
    #   librosa
    #   onnx
    #   openai
    #   pydantic
    #   pydantic-core
    #   starlette
    #   torch
    #   typer
tzdata==2025.3
    # via pandas
urllib3==2.2.3
    # via
    #   gradio
    #   requests
uvicorn==0.40.0 ; sys_platform != 'emscripten'
    # via gradio
virtualenv==20.35.4
    # via pre-commit
wcwidth==0.2.13
    # via prompt-toolkit
websockets==14.1
    # via
    #   elevenlabs
    #   gradio-client
win32-setctime==1.2.0 ; sys_platform == 'win32'
    # via loguru
wrapt==2.0.1
    # via deprecated
zipp==3.23.0
    # via importlib-metadata
